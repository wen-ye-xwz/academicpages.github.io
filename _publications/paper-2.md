---
title: "GPT4MTS: Prompt-based Large Language Model for Multimodal Time-series Forecasting"
collection: publications
permalink: /publication/paper-2
excerpt: ''
date: 2024-2-24
venue: 'EAAI-24 (The 14th Symposium on Educational Advances in Artificial Intelligence)'
authors: '<strong>Furong Jia</strong>, Kevin Wang, Yixiang Zheng, Defu Cao, Yan Liu'
---

Time series forecasting is an essential area of machine learning with a wide range of real-world applications. Most of the previous forecasting models aim to capture dynamic characteristics from uni-modal numerical historical data. Although extra knowledge can boost the time series forecasting performance, it is hard to collect such information. In addition, how to fuse the multimodal information is non-trivial. In this paper, we first propose a general principle of collecting the corresponding textual information from different data sources with the help of modern large language models (LLM). Then, we propose a prompt-based LLM framework to utilize both the numerical data and the textual information simultaneously, named GPT4MTS. In practice, we propose a GDELT-based multimodal time series dataset for news impact forecasting, which provides a concise and well-structured version of time series dataset with textual information for further research in communication. Through extensive experiments, we demonstrate the effectiveness of our proposed method on forecasting tasks with extra-textual information.

[Download paper here](https://ojs.aaai.org/index.php/AAAI/article/view/30383)